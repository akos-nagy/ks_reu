\documentclass[12pt,reqno]{amsart}

%%%%%%%%%% Packages %%%%%%%%%%

\usepackage{amsmath,amssymb,mathtools,verbatim,enumitem,appendix,kpfonts}
%\usepackage[widespace,upright]{fourier}
\usepackage[backrefs]{amsrefs}
\usepackage[protrusion=true,babel=true]{microtype}
\usepackage[english]{babel}
\usepackage[margin=1in]{geometry}
\usepackage[onehalfspacing]{setspace}
\usepackage[pdfusetitle,colorlinks,pagebackref,hypertexnames=false,bookmarks=false]{hyperref}
\numberwithin{equation}{section}							% must call it before cleveref
\usepackage[nameinlink,noabbrev]{cleveref}
\expandafter\def\csname ver@etex.sty\endcsname{3000/12/31}	% this fixes a random, irrelevant warning that clever throws
\let\globcount\newcount
\usepackage{autonum}										% must call after cleveref
\usepackage[T1]{fontenc}

%%%%%%%%%% align break fix %%%%%%%%%%

\allowdisplaybreaks

%%%%%%%%%% Left/Right fix %%%%%%%%%%

\let\originalleft\left
\let\originalright\right
\renewcommand{\left}{\mathopen{}\mathclose\bgroup\originalleft}
\renewcommand{\right}{\aftergroup\egroup\originalright}

%%%%%%%%%% eqref fix %%%%%%%%%%

\makeatletter
\renewcommand*{\eqref}[1]{\hyperref[{#1}]{\textup{\tagform@{\ref*{#1}}}}}
\makeatother

%%%%%%%%%% oxford comma fix %%%%%%%%%%

\newcommand{\creflastconjunction}{, and\nobreakspace}

%%%%%%%%%% coloneqq fix %%%%%%%%%%

\newcommand{\eqdef}{\mathrel{\vcenter{\baselineskip0.5ex\lineskiplimit0pt\hbox{.}\hbox{.}}}=}

%%%%%%%%%% Theorems/numbering %%%%%%%%%%

\newtheorem{theorem}{Theorem}[section]
\newtheorem{Mtheorem}{Main Theorem}
\newtheorem*{acknowledgment}{Acknowledgment}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{hypoth}[theorem]{Hypothesis}
\crefname{theorem}{Theorem}{Theorems}						% label for Theorems
\creflabelformat{theorem}{#2{#1}#3}							% label format for 'theorem'
\crefname{Mtheorem}{Main Theorem}{Main Theorems}			% label for the Main Theorems
\creflabelformat{Mtheorem}{#2{#1}#3}						% label format for 'Mtheorem'
\crefname{lemma}{Lemma}{Lemmata}							% label for Lemmata
\creflabelformat{lemma}{#2{#1}#3}							% label format for 'lemma'
\crefname{corollary}{Corollary}{Corollaries}				% label for Corollaries
\creflabelformat{corollary}{#2{#1}#3}						% label format for 'corollary'
\crefname{theorem}{Proposition}{Propositions}			% label for Propositions
\creflabelformat{theorem}{#2{#1}#3}						% label format for 'theorem'
\crefname{ineq}{inequality}{inequalities}					% label for inequalities
\creflabelformat{ineq}{#2{\upshape(#1)}#3}					% label format for 'ineq'
\crefname{cond}{condition}{conditions}						% label for conditions
\creflabelformat{cond}{#2{\upshape(#1)}#3}					% label format for 'cond'
\crefname{hypoth}{Hypothesis}{Hypotheses}					% label for Hypotheses
\creflabelformat{hypoth}{#2{#1}#3}							% label format for 'hypoth'
\crefname{definition}{Definition}{Definitions}						% label for Definitions
\creflabelformat{def}{#2{#1}#3}								% label format for 'def'
\crefname{appsec}{Appendix}{Appendices}

%%%%%%%%%% Blackboard %%%%%%%%%%

\def\id{\mathbbm{1}}
\def\cx{\mathbb{C}}
\def\rl{\mathbb{R}}
\def\N{\mathbb{N}}
\def\P{\mathbb{P}}
\def\Z{\mathbb{Z}}

%%%%%%%%%% CalligraPhics %%%%%%%%%%

\def\cA{\mathcal{A}}
\def\cB{\mathcal{B}}
\def\cC{\mathcal{C}}
\def\cD{\mathcal{D}}
\def\cE{\mathcal{E}}
\def\cF{\mathcal{F}}
\def\cG{\mathcal{G}}
\def\cH{\mathcal{H}}
\def\cI{\mathcal{I}}
\def\cJ{\mathcal{J}}
\def\cK{\mathcal{K}}
\def\cL{\mathcal{L}}
\def\cM{\mathcal{M}}
\def\cN{\mathcal{N}}
\def\cO{\mathcal{O}}
\def\cP{\mathcal{P}}
\def\cQ{\mathcal{Q}}
\def\cR{\mathcal{R}}
\def\cS{\mathcal{S}}
\def\cT{\mathcal{T}}
\def\cU{\mathcal{U}}
\def\cV{\mathcal{V}}
\def\cW{\mathcal{W}}
\def\cZ{\mathcal{Z}}

%%%%%%%%%% Romans %%%%%%%%%%

\def\Ar{\mathrm{Area}}
\def\dist{\mathrm{dist}}
\def\Im{\mathrm{Im}}
\def\image{\mathrm{image}}
\def\Re{\mathrm{Re}}
\def\sign{\textsc{sign}}
\def\Spec{\mathrm{Spec}}
\def\supp{\mathrm{supp}}
\def\tr{\mathrm{tr}}

%%%%%%%%%% Other symbols (paper specific) %%%%%%%%%%

\def\del{\partial}
\def\delbar{\overline{\partial}}
\def\rd{\operatorname{d\!}{}}
\def\dA{\: \rd A}
\def\TBC{\underline{\textbf{To be completed.}}}

%%%%%%%%%% Other formatting %%%%%%%%%%

\title{The Keller--Segel equation compact surfaces}
\date{\today}
\keywords{Keller--Segel equations}
\keywords{chemotaxis, Keller--Segel equations}
\subjclass[2020]{35J15, 35Q92, 92C17}

\author{Adam Mendenhall}
\address[Adam Mendenhall]{University of California, Santa Barbara}
\email{\href{amendenhall@ucsb.edu}{amendenhall@ucsb.edu}}

\author{\'Akos Nagy}
\address[\'Akos Nagy]{University of California, Santa Barbara}
\email{\href{contact@akosnagy.com}{contact@akosnagy.com}}
\urladdr{\href{https://akosnagy.com}{akosnagy.com}}

\calclayout
\pagestyle{plain}
\clubpenalty = 10000
\widowpenalty = 10000
\setlength{\footskip}{20pt}

\hypersetup{
	unicode			= true,
	pdffitwindow	= true,
	pdftoolbar		= false,
	pdfmenubar		= false,
	pdfstartview	= {FitH},
	hypertexnames	= false,
	colorlinks		= true,
	linkcolor		= black,
	citecolor		= black,
	filecolor		= black,
	urlcolor		= blue
}

\newcommand{\ul}{\underline l}
\newcommand{\uk}{\underline k}
\newcommand{\uj}{\underline j}

\begin{document}

\begin{abstract}
	We study the (parabolic-elliptic) Keller--Segel equations on compact surfaces.

	\TBC
\end{abstract}

\maketitle

\section{Introduction}

\TBC {\color{red} This is the part that we will write last.}

\medskip

\subsection*{Organization of the paper}

\TBC

\medskip

\begin{acknowledgment}
	\TBC
\end{acknowledgment}

\bigskip

\section{Reformulation of the equation}

Let $\Sigma$ be a smooth, closed surface with a Riemannian metric $g$ and area form $\omega$. Let $G$ be the Green operator of the Laplacian, $\Delta$, on $L^2 \left( \Sigma, g \right)$ and let us fix $\varrho_0 \in L^2 \left( \Sigma, g \right)$. Note that $L^2 \hookrightarrow L^1$ on domains of finite measure. We say that a positive function, $\varrho \in C^1 \left( (0, T); L^2 \left( \Sigma, g \right) \right)$ is said to satisfy the \emph{parabolic--elliptic Keller--Segel equations} on $\left( \Sigma, g \right)$ with initial value $\varrho_0$ if it is a solution to the following system:
\begin{subequations}
\begin{align}
	\del_t \varrho								&= - \Delta \varrho + \rd^* \left( \varrho \rd G \left( \varrho \right) \right), \label{eq:KS_eq} \\
	\lim\limits_{t \rightarrow 0^+} \varrho_t	&= \varrho_0. \label{eq:KS_IV}
\end{align}
\end{subequations}
where for all $t \in (0, T)$
\begin{equation}
	 \varrho_t \eqdef \varrho|_{\{ t \} \times \Sigma},
\end{equation}
regarded as a function in $L^2 \left( \Sigma, g \right)$.

Now let
\begin{equation}
	M (t) \eqdef \int\limits_\Sigma \varrho_t \dA.
\end{equation}
Then $M$ is constant, because
\begin{equation}
	\dot{M} (t) = \int\limits_\Sigma \left( - \Delta \varrho + \rd^* \left( \varrho \rd G \left( \varrho \right) \right) \right) \dA = \int\limits_\Sigma \rd^* \left( - \rd \varrho + \varrho \rd G \left( \varrho \right) \right) \dA = 0.
\end{equation}
Thus we drop the $t$-dependence of $M$ from its notation.

\smallskip

For the rest of the paper, let $A_\Sigma \eqdef \Ar \left( \Sigma, g \right)$. The following lemma recasts \cref{eq:KS_eq,eq:KS_IV} in a simpler form.

\begin{lemma}
	Let $\chi_0 \coloneqq \varrho_0 - \tfrac{M}{A_\Sigma}$ and $\chi \coloneqq \varrho - \tfrac{M}{A_\Sigma}$. Then \cref{eq:KS_eq,eq:KS_IV} is equivalent to
	\begin{subequations}
	\begin{align}
		\del_t \chi						&= \tfrac{M}{A_\Sigma} \chi - \Delta \chi + \rd^* \left( \chi \rd G \left( \chi \right) \right), \label{eq:new_KS_eq} \\
		\chi|_{\{ 0 \} \times \Sigma}	&= \chi_0. \label{eq:new_KS_IV}
	\end{align}
	\end{subequations}
\end{lemma}

\begin{proof}
	The equivalency of \cref{eq:KS_IV} and \cref{eq:new_KS_IV} is obvious.

	Note that $G$ annihilates constants and since $\chi$ is orthogonal to constants, we have that $\Delta \left( G \left( \chi \right) \right) = \chi$. Since $\chi = \varrho - \tfrac{M}{A_\Sigma}$, we get, using \cref{eq:KS_eq}, that
	\begin{align}
		\del_t \chi	&= \del_t \left( \varrho - \tfrac{M}{A_\Sigma} \right) \\
					&= \del_t \varrho - 0 \\
					&= - \Delta \varrho + \rd^* \left( \varrho \rd G \left( \varrho \right) \right) \\
					&= - \Delta \left( \tfrac{M}{A_\Sigma} + \chi \right) + \rd^* \left( \left( \tfrac{M}{A_\Sigma} + \chi \right) \rd G \left( \tfrac{M}{A_\Sigma} + \chi \right) \right) \\
					&= - \Delta \chi + \rd^* \left( \left( \tfrac{M}{A_\Sigma} + \chi \right) \rd G \left( \chi \right) \right) \\
					&= - \Delta \chi + \tfrac{M}{A_\Sigma} \rd^* \rd G \left( \chi \right) + \rd^* \left( \chi \rd G \left( \chi \right) \right) \\
					&= \tfrac{M}{A_\Sigma} \chi - \Delta \chi + \rd^* \left( \chi \rd G \left( \chi \right) \right),
	\end{align}
	which completes the proof.
\end{proof}

\smallskip

\begin{remark}
	Let $\lambda_1$ be the smallest nonzero eigenvalue of $\Delta$ and note that quantity $M_\Sigma = \lambda_1 A_\Sigma$ only depends on the geometry of $\left( \Sigma, g \right)$. When $M < M_\Sigma$, then the linear term in \cref{eq:new_KS_eq} is strictly negative definite.
\end{remark}

\bigskip

\section{The generalized Fourier transform}

Let now $\left( \Psi_a \in L^2 \left( \Sigma, g \right) \right)_{a \in \N}$ be an orthonormal eigenbasis of $\Delta$ and
\begin{equation}
	\Delta \Psi_a = \lambda_a \Psi_a.
\end{equation}
Let us order this basis so that
\begin{equation}
	0 = \lambda_0 < \lambda_1 \leqslant \lambda_2 \leqslant \ldots \lambda_a \leqslant \lambda_{a + 1} \leqslant \ldots
\end{equation}
In particular, $\Psi_0 = \tfrac{1}{\sqrt{A_\Sigma}}$.

Assume that $\chi$ is a solution to \cref{eq:new_KS_eq,eq:new_KS_IV} and write
\begin{equation}
	R_a (t) \eqdef \left\langle \Psi_a \middle| \chi|_{\{ t \} \times \Sigma} \right\rangle_{L^2 \left( \Sigma, g \right)}.
\end{equation}
Then for each $a \in \N$, we have that $R_a \in C^1 \left( (0, T); \rl \right)$. Note that $R_0 \equiv \tfrac{M}{A_\Sigma}$. Finally let
\begin{equation}
	\forall a, b, c \in \N : \quad \varphi_{abc} \coloneqq \int\limits_\Sigma \Psi_a \Psi_b \Psi_c \dA.
\end{equation}
Note that $\varphi_{abc}$ is a completely symmetric 3-tensor.

\smallskip

\begin{theorem}
\label{theorem:ODE}
	The function $\varrho$ is a solution to \cref{eq:KS_eq} exactly when
	\begin{subequations}
	\begin{align}
		\forall t \in (0, T) &: \quad \left( R_a (t) \right)_{a \in \N} \in l^2 \left( \N \right), \label[cond]{cond:R_l2} \\
		\forall a \in \N_+ &: \quad \dot{R}_a = \left( \tfrac{M}{A_\Sigma} - \lambda_a \right) R_a + \sum\limits_{b, c \in \N} \frac{\lambda_a - \lambda_b + \lambda_c}{2 \lambda_c} \varphi_{abc} R_b R_c. \label{eq:R_a_eq}
	\end{align}
	\end{subequations}
	Furthermore, if \cref{eq:KS_IV} is also satisfied, then for all $a \in \N$, $\lim_{t \rightarrow 0^+} R_a (t)$ exists and
	\begin{equation}
		\varrho_0 = \sum\limits_{a \in \N} \left( \lim\limits_{t \rightarrow 0^+} R_a (t) \right) \Psi_a. \label{eq:R_a_IV}
	\end{equation}
\end{theorem}

\begin{proof}
	Since $\left( \Psi_a \right)_{a \in \N}$ is an orthonormal basis of $L^2 \left( \Sigma, g \right)$ and for all $t \in (0, T)$, $\varrho_t$ is in $L^2 \left( \Sigma, g \right)$, we get \cref{cond:R_l2}.

	Fix $a \in \N_+$. Then
	\begin{equation}
		G \left( \Psi_a \right) = \lambda_a^{- 1} \Psi_a.
	\end{equation}
	Using the above equation, the self-adjointness of $\Delta$, and \cref{eq:new_KS_eq}, we get
	\begin{align}
		\dot{R}_a	&= \left\langle \Psi_a \middle| \partial_t \chi \right\rangle_{L^2 \left( \Sigma, g \right)} \\
					&= \left\langle \Psi_a \middle| \tfrac{M}{A_\Sigma} \chi - \Delta \chi + \rd^* \left( \chi \rd G \left( \chi \right) \right) \right\rangle_{L^2 \left( \Sigma, g \right)} \\
					&= \left\langle \tfrac{M}{A_\Sigma} \Psi_a - \Delta \Psi_a \middle| \chi \right\rangle_{L^2 \left( \Sigma, g \right)} + \left\langle \rd \Psi_a \middle| \chi \rd G \left( \chi \right) \right\rangle_{L^2 \left( \Sigma, g \right)} \\
					&= \left( \tfrac{M}{A_\Sigma} - \lambda_a \right) \left\langle \Psi_a \middle| \chi \right\rangle_{L^2 \left( \Sigma, g \right)} + \sum\limits_{b, c \in \N_+} \left\langle \rd \Psi_a \middle| \Psi_b \rd G \left( \Psi_c \right) \right\rangle_{L^2 \left( \Sigma, g \right)} R_b R_c \\
					&= \left( \tfrac{M}{A_\Sigma} - \lambda_a \right) R_a + \sum\limits_{b, c \in \N_+} \left\langle \rd \Psi_a \middle| \Psi_b \rd \Psi_c \right\rangle_{L^2 \left( \Sigma, g \right)} \lambda_c^{- 1} R_b R_c. \label{eq:coeffs}
	\end{align}
	Note that
	\begin{equation}
		\left\langle \rd \Psi_a \middle| \Psi_b \rd \Psi_c \right\rangle_{L^2 \left( \Sigma, g \right)} = \int\limits_\Sigma \Psi_b g \left( \rd \Psi_a, \rd \Psi_c \right) \dA, \label{eq:triple_coeff}
	\end{equation}
	and
	\begin{equation}
		\Delta \left( \Psi_a \Psi_c \right) = \left( \Delta \Psi_a \right) \Psi_c + \Psi_a \left( \Delta \Psi_c \right) - 2 g \left( \rd \Psi_a, \rd \Psi_c \right) = \left( \lambda_a + \lambda_c \right) \Psi_a \Psi_c - 2 g \left( \rd \Psi_a, \rd \Psi_c \right).
	\end{equation}
	Thus
	\begin{equation}
		g \left( \rd \Psi_a, \rd \Psi_c \right) = \frac{\lambda_a + \lambda_c}{2} \Psi_a \Psi_c - \frac{1}{2} \Delta \left( \Psi_a \Psi_c \right).
	\end{equation}
	Plugging the above equation into \cref{eq:triple_coeff} we get
	\begin{align}
		\left\langle \rd \Psi_a \middle| \Psi_b \rd \Psi_c \right\rangle_{L^2 \left( \Sigma, g \right)}	&= \int\limits_\Sigma \Psi_b g \left( \rd \Psi_a, \rd \Psi_c \right) \dA \\
			&= \int\limits_\Sigma \Psi_b \left( \frac{\lambda_a + \lambda_c}{2} \Psi_a \Psi_c - \frac{1}{2} \Delta \left( \Psi_a \Psi_c \right) \right) \dA \\
			&= \frac{\lambda_a + \lambda_c}{2} \varphi_{abc} - \frac{1}{2} \int\limits_\Sigma \left( \Delta \Psi_b \right) \Psi_a \Psi_c \dA \\
			&= \frac{\lambda_a + \lambda_c}{2} \varphi_{abc} - \frac{\lambda_b}{2} \int\limits_\Sigma \Psi_b \Psi_a \Psi_c \dA \\
			&=  \frac{\lambda_a - \lambda_b + \lambda_c}{2} \varphi_{abc}.
	\end{align}
	Inserting this into \cref{eq:coeffs} yields \cref{eq:R_a_eq}.

	The equivalency of \cref{eq:KS_IV} and \cref{eq:R_a_IV} is straightforward.
\end{proof}

\smallskip

\begin{remark}
	The moral of \Cref{theorem:ODE} is that the Keller--Segel equations, which is a (hard) elliptic-parabolic system of partial differential equations, can be transformed (on closed surfaces) into a infinite system of ordinary differential equations, which is potentially easier to handle.

	In the rest of the paper we show that this system can be further simplified under certain extra hypotheses.
\end{remark}

\smallskip

\subsection{Analytic solutions}

In order to further simplify \cref{eq:R_a_eq}, we search for analytic solutions, that is
\begin{equation}
	\forall a \in \N : \forall t \in (0, T): \quad R_a (t) = \sum\limits_{n \in \N} R_{a, n} t^n, \label{eq:analycity}
\end{equation}
and the right-hand side is assumed to be absolute convergent in $l^2 \left( \N \right)$.

The next lemma rewrites \cref{eq:R_a_eq} in terms of the coefficients $\left( R_{a, n} \right)_{(a, n) \in \N \times \N}$.

\begin{lemma}
	Under the above assumption, the function $\varrho$ is a $t$-analytic solution to \cref{eq:KS_eq} with mass $M$ exactly when $R_{0, 0} = \tfrac{M}{A_\Sigma}$, for all $n \in \N_+$, $R_{0, n} = 0$, and
	\begin{subequations}
	\begin{align}
		\forall a, n \in \N	&: \quad R_{a, n + 1} = \frac{1}{n + 1} \left( \left( \tfrac{M}{A_\Sigma} - \lambda_a \right) R_{a, n} + \sum\limits_{b, c \in \N_+} \sum\limits_{m = 0}^n \tfrac{\lambda_a - \lambda_b + \lambda_c}{2 \lambda_c} \varphi_{abc} R_{b, m} R_{c, n - m} \right), \label{eq:general_iteration} \\
		\forall n \in \N	&: \quad \cR_n \coloneqq \left( R_{a, n} \right)_{a \in \N} \in l^2 \left( \N \right), \label{eq:regularity} \\
		& \qquad \limsup\limits_{n \rightarrow \infty} \| \cR_n \|_{l^2 \left( \N \right)}^{\frac{1}{n}} = \limsup\limits_{n \rightarrow \infty} \left( \sum\limits_{a \in \N} R_{a, n}^2 \right)^{\frac{1}{n}} < \frac{1}{T}. \label{eq:convergence_radius}
	\end{align}
	\end{subequations}
\end{lemma}

\begin{proof}
	Inserting \cref{eq:analycity} into \cref{eq:R_a_eq} yields \cref{eq:general_iteration}. The \cref{eq:regularity,eq:convergence_radius} are necessary (and, in fact, sufficient) to have that the convergence radius of the Taylor series of $\varrho$ in the $L^2$ topology is at least $T$.
\end{proof}

In the following two sections we investigate two special cases when iteration in \cref{eq:general_iteration} exists for all $a$ and $n$.

\bigskip

\section{Round spheres}
\label{sec:sphere}

Let $\Sigma$ be the 2-sphere and $g$ be the round metric of radius $r$. Then we have that $\left( \Psi_a \right)_{a \in \N}$ are the spherical harmonics. Then $A_\Sigma = 4 \pi r^2$. In fact, after relabeling them, we can write the eigenvalue has the form $\lambda_{l, m} \eqdef \tfrac{l (l + 1)}{r^2}$, where $l \in \N$ and $M$ is any integer satisfying $|m| \leqslant l$. Let us now write
\begin{equation}
	\Psi_l^m \eqdef \Psi_{(l, m)}, \quad \& \quad R_{l, a}^m \eqdef R_{(l, m), a}, \quad \& \quad \varphi_{l_1, l_2, l_3}^{m_1, m_2, m_3} \eqdef \varphi_{(l_1, m_1), (l_2, m_2), (l_3, m_3)}.
\end{equation}
Using this new set of indices and notation, we can rewrite \cref{eq:general_iteration} as
\begin{align}
	R_{l, n + 1}^m	&= \frac{1}{n + 1} \left( \tfrac{M}{4 \pi r^2} - \tfrac{l (l + 1)}{r^2} \right) R_{(l, m), n} \\
					& \quad + \sum\limits_{l_1, l_2 \in \N_+} \sum\limits_{m_1 = - l_1}^{l_1} \sum\limits_{m_2 = - l_2}^{l_2} \sum\limits_{x = 0}^n \tfrac{l (l + 1) - l_1 (l_1 + 1) + l_2 (l_2 + 1)}{2 (n + 1) l_2 (l_2 + 1)} \varphi_{l, l_1, l_2}^{m, m_1, m_2} R_{l_1, x}^{m_1} R_{l_2, n - x}^{m_2}. \label{eq:iteration_on_S2_naive}
\end{align}
Using the Clebsch--Gordan Theorem, we have that if $l_1 \geqslant l_2 + l_3$ or $l_1 \leqslant |l_2 - l_3|$, then for all $m_1, m_2$, and $m_3$, we have $\varphi_{l_1, l_2, l_3}^{m_1, m_2, m_3} = 0$. Thus \cref{eq:iteration_on_S2_naive} becomes
\begin{align}
	R_{l, n + 1}^m	&= \frac{1}{n + 1} \left( \tfrac{M}{4 \pi r^2} - \tfrac{l (l + 1)}{r^2} \right) R_{l, n}^m \\
					& \quad + \sum\limits_{l_1 \in \N_+} \sum\limits_{l_2 = \max \left( \{ 1, |l - l_1| \} \right)}^{l + l_1} \sum\limits_{m_1 = - l_1}^{l_1} \sum\limits_{m_2 = - l_2}^{l_2} \sum\limits_{x = 0}^n \tfrac{l (l + 1) - l_1 (l_1 + 1) + l_2 (l_2 + 1)}{2 (n + 1) l_2 (l_2 + 1)} \varphi_{l, l_1, l_2}^{m, m_1, m_2} R_{l_1, x}^{m_1} R_{l_2, n - x}^{m_2}. \label{eq:iteration_on_S2}
\end{align}

Before prove the main result of this section, let us make the following definition:
\begin{equation}
	\forall n \in \N : \quad Z_n \eqdef \left\{ \ (l, m) \in \N \times \Z \ \middle| \ R_{l, n}^m \neq 0 \ \right\}.
\end{equation}

\begin{theorem}
	Assume that $Z_0$ is finite. Then for all $(l, m) \in \N \times \Z$ and $n \in \N$, $R_{l, n}^m$ exists. Furthermore, $Z_n$ is also finite, and \cref{eq:iteration_on_S2} becomes
	\begin{align}
		R_{l, n + 1}^m	&= \frac{1}{n + 1} \left( \tfrac{M}{4 \pi r^2} - \tfrac{l (l + 1)}{r^2} \right) R_{l, n}^m \\
						& \quad + \sum\limits_{x = 0}^n \sum\limits_{\substack{(l_1, m_1) \in Z_x \\ (l_2, m_2) \in Z_{n - x}}} \tfrac{l (l + 1) - l_1 (l_1 + 1) + l_2 (l_2 + 1)}{2 (n + 1) l_2 (l_2 + 1)} \varphi_{l, l_1, l_2}^{m, m_1, m_2} R_{l_1, x}^{m_1} R_{l_2, n - x}^{m_2}. \label{eq:iteration_on_S2_finite}
	\end{align}
\end{theorem}

\begin{proof}
	Let us prove by induction.

	Since the claim for $n = 0$ is the hypothesis of the theorem, we only need to assume that we have already prove the claim for all nonnegative integers up to and including $n \in \N_+$.

	The right-hand side of \cref{eq:iteration_on_S2} contains coefficients of the form $R_{l_1, x}^{m_1}$ and $R_{l_2, n - x}^{m_2}$, with $0 \leqslant x \leqslant n$, we have that $R_{l_1, x}^{m_1}$ unless $(l_1, m_1) \in Z_x$ and $R_{l_2, n - x}^{m_2}$ unless $(l_2, m_2) \in Z_{n - x}$. Thus for every $x$ we have the contribution of a finite sum, and we only consider finitely many $x$'s, this proves \cref{eq:iteration_on_S2_finite}.

	Since now $R_{l, n + 1}^m$ is expressed as a finite sum, it exists, which concludes the proof.
\end{proof}

\bigskip

\section{Flat tori}

Let now $\Sigma$ be a flat torus. Thus, without any loss of generality, we can assume that there are vectors
\begin{equation}
	\underline{e}_1 = \begin{pmatrix} L_1 \\ 0 \end{pmatrix}, \quad \& \quad \underline{e}_2 = \begin{pmatrix} L_2 \cos (\theta) \\ L_2 \sin (\theta) \end{pmatrix}.
\end{equation}
such that, if we define the \emph{lattice} $\Lambda \eqdef \Z \underline{e}_1 \oplus \Z \underline{e}_2$, then
\begin{equation}
	\Sigma = \rl^2 / \Lambda.
\end{equation}
Note that $A_\Sigma = L_1 L_2 \sin (\theta)$. Let the \emph{dual} lattice be
\begin{equation}
	\Lambda^* \eqdef \left\{ \ \underline{k} \in \rl^2 \ \middle| \ \forall \underline{x} \in \Lambda : \ \underline{k} \cdot \underline{x} \in \Z \ \right\}.
\end{equation}
It is easy to see that if
\begin{equation}
	\underline{f}_1 \eqdef \begin{pmatrix} \tfrac{1}{L_1} \\ - \tfrac{\cot (\theta)}{L_1} \end{pmatrix}, \quad \& \quad \underline{f}_2 = \begin{pmatrix} 0 \\ \tfrac{1}{L_2 \sin (\theta)} \end{pmatrix}.
\end{equation}
then $\underline{e}_i \cdot \underline{f}_j = \delta_{i, j}$ and thus
\begin{equation}
	\Lambda^* = \Z \underline{f}_1 \oplus \Z \underline{f}_2.
\end{equation}

Now let
\begin{equation}
	\forall \underline{x} \in \Sigma : \forall \underline{k} \in \Lambda^* : \quad \Psi_{\underline{k}} \left( \underline{x} \right) \eqdef \frac{1}{\sqrt{A_\Sigma}} e^{2 \pi i \underline{k} \cdot \underline{x}}.
\end{equation}
Then $\left( \Psi_{\underline{k}} \right)_{\underline{k} \in \Lambda^*}$ is an orthonormal basis for the \emph{complex} Hilbert space $L_\cx^2 \left( \Sigma, g \right)$. Furthermore, note that $\Psi_{\underline{k}} = \overline{\Psi_{- \underline{k}}}$. Finally, note that
\begin{equation}
	\Delta \Psi_{\underline{k}} = 4 \pi^2 \left| \underline{k} \right|^2 \Psi_{\underline{k}},
\end{equation}
thus $\left( \Psi_{\underline{k}} \right)_{\underline{k} \in \Lambda^*}$ is an eigenbasis for the Laplacian, albeit a complex one. The corresponding spectrum is $\left( 4 \pi^2 \left| \underline{k} \right|^2 \right)_{\underline{k} \in \Lambda^*}$.

Function on $\Sigma$ can be viewed as $\Lambda$-periodic functions on $\rl^2$, thus if $\varrho$ is an ($L_\cx^2$) function on $\Sigma$, then we use Fourier decomposition to get:
\begin{equation}
	\forall \underline{k} \in \Lambda^* : \quad R_{\underline{k}} \eqdef \frac{1}{\sqrt{A_\Sigma}} \int\limits_\Sigma e^{- 2 \pi i \underline{k} \cdot \underline{x}} \varrho \left( \underline{x} \right) \dA \left( \underline{x} \right), \quad \Leftrightarrow \quad \varrho = \sum\limits_{\underline{k} \in \Lambda^*} R_{\underline{k}} \Psi_{\underline{k}}.
\end{equation}
If $\varrho$ is real, then $R_{\underline{k}} = \overline{R_{- \underline{k}}}$. In this section we slightly deviate from our previous method and use the above complex basis and coefficients.

The ideas and proofs of the previous sections still apply, and if $\varrho \in C^1 \left( (0, T), L_\cx^2 \left( \Sigma, g \right) \right)$, then we can define the coefficients functions $R_{\underline{k}} \in C_\cx^1 \left( \Sigma \right)$, so that
\begin{equation}
	\varrho \left( t, \underline{x} \right) = \sum\limits_{n \in \N} \sum\limits_{\underline{k} \in \Lambda^*} R_{\underline{k}} (t) \Psi_{\underline{k}} \left( \underline{x} \right).
\end{equation}
If, furthermore, $\varrho$ is a solution to the Keller--Segel \cref{eq:KS_eq}, then we get (after a straightforward computation) that
\begin{equation}
	\dot{R}_{\underline{k}} = \left( \tfrac{M}{A_\Sigma} - 4 \pi^2 \left| \underline{k} \right|^2 \right) R_{\underline{k}} + \sum\limits_{\underline{l} \in \Lambda^*} \frac{\underline{k} \cdot \underline{l}}{\left| \underline{l} \right|^2} R_{\underline{l}} R_{\underline{k} - \underline{l}}.
\end{equation}
Finally, if $\varrho$ is analytic in $t$, and we define $R_{n, \underline{k}} \in \cx$ as
\begin{equation}
	R_{\underline{k}} (t) = \sum\limits_{n \in \N} R_{n, \underline{k}} t^n,
\end{equation}
then we get the corresponding iteration for these coefficients to be
\begin{equation}
	R_{n + 1, \underline{k}} = \frac{1}{n + 1} \left( \left( \tfrac{M}{A_\Sigma} - 4 \pi^2 \left| \underline{k} \right|^2 \right) R_{n, \underline{k}} + \sum\limits_{\underline{l} \in \Lambda^*} \sum\limits_m^n \frac{\underline{k} \cdot \underline{l}}{\left| \underline{l} \right|^2} R_{m, \underline{l}} R_{n - m, \underline{k} - \underline{l}} \right). \label{eq:iteration_on_torus}
\end{equation}

As in \Cref{sec:sphere}, let us make the following definition:
\begin{equation}
	\forall n \in \N : \quad Z_n \eqdef \left\{ \ \underline{k} \in \Lambda^* \ \middle| \ R_{n, \underline{k}} \neq 0 \ \right\}.
\end{equation}
Since we assume that $M \neq 0$, we have that $\underline{0} \in Z_n$.

\begin{theorem}
	\label{theorem:torus_finite}
	Assume that $Z_0$ is finite. Then for all $\underline{k} \in \Lambda^*$ and $n \in \N$, $R_{n, \underline{k}}$ exists. Moreover, $Z_n$ is also finite and satisfies
	\begin{equation}
		Z_n \subseteq Z_{n - 1} + Z_{n - 1}, \label{eq:Z_n_iteration}
	\end{equation}
	and \cref{eq:iteration_on_torus} becomes
	\begin{equation}
		R_{n + 1, \underline{k}} = \frac{1}{n + 1} \left( \left( \tfrac{M}{A_\Sigma} - 4 \pi^2 \left| \underline{k} \right|^2 \right) R_{n, \underline{k}} + \sum\limits_{\substack{\underline{l} \in Z_m \\ \underline{k} - \underline{l} \in Z_{n - m}}} \sum\limits_m^n \frac{\underline{k} \cdot \underline{l}}{\left| \underline{l} \right|^2} R_{m, \underline{l}} R_{n - m, \underline{k} - \underline{l}} \right). \label{eq:iteration_on_torus_finite}
	\end{equation}
	Finally, let
	\begin{equation}
		d \eqdef \max \left( \left\{ \ \left| \underline{k} \right| \ \middle| \ \underline{k} \in Z_0 \ \right\} \right) > 0.
	\end{equation}
	Then
	\begin{equation}
		d_n \eqdef \max \left( \left\{ \ \left| \underline{k} \right| \ \middle| \ \underline{k} \in Z_n \ \right\} \right) \leqslant 2^n d.
	\end{equation}
\end{theorem}

\begin{proof}
	Let us prove by induction.

	Since the claim for $n = 0$ is the hypothesis of the theorem, we only need to assume that we have already prove the claim for all nonnegative integers up to and including $n \in \N_+$.

	The right-hand side of \cref{eq:iteration_on_torus} contains coefficients of the form $R_{m, \underline{l}}$ and $R_{n - m, \underline{k} - \underline{l}}$, with $0 \leqslant m \leqslant n$, we have that $R_{m, \underline{l}} = 0$ unless $\underline{l} \in Z_m$ and $R_{n - m, \underline{k} - \underline{l}} = 0$ unless $\underline{k} - \underline{l} \in Z_{n - m}$. That proves \cref{eq:iteration_on_torus_finite}.

	Since now $R_{n + 1, \underline{k}}$ is expressed as a finite sum, it exists.

	Now let $Z_{n + 1}^\prime \eqdef Z_n + Z_n$. If $\underline{k} \in \Lambda^* - Z_{n + 1}^\prime$, then for all $m \in \N$, such that $0 \leqslant m \leqslant n$, there does now exists $\underline{k} \in Z_m$ that could also satisfy $\underline{k} - \underline{l} \in Z_{n - m}$. Furthermore, since $Z_n \subseteq Z_{n + 1}^\prime$ we also have that $\underline{k} \notin Z_n$. Thus all terms in \cref{eq:iteration_on_torus_finite} are zero, and hence $\underline{k} \in Z_{n + 1}$, which proves \cref{eq:Z_n_iteration}.

	Finally, if $\underline{k} \in Z_{n + 1}$, then there exist $\underline{l}_1, \underline{l}_2 \in Z_n$, such that $\underline{k} = \underline{l}_1 + \underline{l}_2$. Thus
	\begin{equation}
		\left| \underline{k} \right|  = \left| \underline{l}_1 + \underline{l}_2 \right| \leqslant \left| \underline{l}_1 \right| + \left| \underline{l}_2 \right| \leqslant 2^n d + 2^n d = 2^{n + 1} d,
	\end{equation}
	which concludes the proof.
\end{proof}

\smallskip

\begin{remark}
	Under the assumptions of \Cref{theorem:torus_finite} we also have
	\begin{equation}
		|Z_n| \leqslant \pi \left( 2^n d \right)^2 A_\Sigma.
	\end{equation}
	Let $C \eqdef \pi d L_1 L_2 \sin (\theta)$, which only depends on the "input" parameters. Then
	\begin{equation}
		|Z_n| \leqslant C 4^n.
	\end{equation}
\end{remark}

\bigskip

\section{Solutions on $\rl^2 / \Z^2$}

*If we figure this out.*

	%=========================
	%\bibliography{references}
	%=========================

\end{document}